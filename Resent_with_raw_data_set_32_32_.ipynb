{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resent with raw data set 32*32 .ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iEHX2cQWlDq",
        "colab_type": "code",
        "outputId": "18148bb6-62e1-4fd9-e70a-7cac20524a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpytfrbAXKQ2",
        "colab_type": "code",
        "outputId": "f52a1be2-9f58-44da-eda8-0f15aa0a9f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/Dastset\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWJskG1uu_k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rgse5Y5Xa9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import numpy as np \n",
        "import torchvision.transforms as transforms \n",
        "import torchvision \n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASDO6qBgwLkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "import torchvision \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pdb\n",
        "\n",
        "torch.set_printoptions(linewidth=120)\n",
        "torch.set_grad_enabled(True) \n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL_Pb6ugXfe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class baseBlock(torch.nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self,input_planes,planes,stride=1,dim_change=None):\n",
        "        super(baseBlock,self).__init__()\n",
        "        #declare convolutional layers with batch norms\n",
        "        self.conv1 = torch.nn.Conv2d(input_planes,planes,stride=stride,kernel_size=3,padding=1)\n",
        "        self.bn1   = torch.nn.BatchNorm2d(planes)\n",
        "        self.conv2 = torch.nn.Conv2d(planes,planes,stride=1,kernel_size=3,padding=1)\n",
        "        self.bn2   = torch.nn.BatchNorm2d(planes)\n",
        "        self.dim_change = dim_change\n",
        "    def forward(self,x):\n",
        "        #Save the residue\n",
        "        res = x\n",
        "        output = F.relu(self.bn1(self.conv1(x)))\n",
        "        output = self.bn2(self.conv2(output))\n",
        "\n",
        "        if self.dim_change is not None:\n",
        "            res = self.dim_change(res)\n",
        "        \n",
        "        output += res\n",
        "        output = F.relu(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyQ4SKnUXg7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bottleNeck(torch.nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self,input_planes,planes,stride=1,dim_change=None):\n",
        "        super(bottleNeck,self).__init__()\n",
        "\n",
        "        self.conv1 = torch.nn.Conv2d(input_planes,planes,kernel_size=1,stride=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
        "        self.conv2 = torch.nn.Conv2d(planes,planes,kernel_size=3,stride=stride,padding=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
        "        self.conv3 = torch.nn.Conv2d(planes,planes*self.expansion,kernel_size=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(planes*self.expansion)\n",
        "        self.dim_change = dim_change\n",
        "    \n",
        "    def forward(self,x):\n",
        "        res = x\n",
        "        \n",
        "        output = F.relu(self.bn1(self.conv1(x)))\n",
        "        output = F.relu(self.bn2(self.conv2(output)))\n",
        "        output = self.bn3(self.conv3(output))\n",
        "\n",
        "        if self.dim_change is not None:\n",
        "            res = self.dim_change(res)\n",
        "        \n",
        "        output += res\n",
        "        output = F.relu(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU8uUkKOXiXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(torch.nn.Module):\n",
        "    def __init__(self,block,num_layers,classes=2):\n",
        "        super(ResNet,self).__init__()\n",
        "        #according to research paper:\n",
        "        self.input_planes = 64\n",
        "        self.conv1 = torch.nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n",
        "        self.bn1   = torch.nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._layer(block,64,num_layers[0],stride=1)\n",
        "        self.layer2 = self._layer(block,128,num_layers[1],stride=2)\n",
        "        self.layer3 = self._layer(block,256,num_layers[2],stride=2)\n",
        "        self.layer4 = self._layer(block,512,num_layers[3],stride=2)\n",
        "        self.averagePool = torch.nn.AvgPool2d(kernel_size=4,stride=1)\n",
        "        self.fc    =  torch.nn.Linear(512*block.expansion,classes)\n",
        "    \n",
        "    def _layer(self,block,planes,num_layers,stride=1):\n",
        "        dim_change = None\n",
        "        if stride!=1 or planes != self.input_planes*block.expansion:\n",
        "            dim_change = torch.nn.Sequential(torch.nn.Conv2d(self.input_planes,planes*block.expansion,kernel_size=1,stride=stride),\n",
        "                                             torch.nn.BatchNorm2d(planes*block.expansion))\n",
        "        netLayers =[]\n",
        "        netLayers.append(block(self.input_planes,planes,stride=stride,dim_change=dim_change))\n",
        "        self.input_planes = planes * block.expansion\n",
        "        for i in range(1,num_layers):\n",
        "            netLayers.append(block(self.input_planes,planes))\n",
        "            self.input_planes = planes * block.expansion\n",
        "        \n",
        "        return torch.nn.Sequential(*netLayers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = F.avg_pool2d(x,4)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulTn-NUIXjs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir =  \"/content/drive/My Drive/Dastset\"\n",
        "train_dir = data_dir + '/train'\n",
        "test_dir = data_dir + '/test'\n",
        "using_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeGWyIFXXp_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "        #To convert data from PIL to tensor\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mnwKGQDXsJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train  = torchvision.datasets.ImageFolder(train_dir, transform = transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1OcI5HCXtnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torch.utils.data.DataLoader(train,batch_size=10,shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6DqkpNfXu-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test  = torchvision.datasets.ImageFolder(test_dir, transform = transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI9iQKM3XwcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = torch.utils.data.DataLoader(test,batch_size=10,shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anWfThdTuJbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('benign','malignant')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ_F5GY_Xx7E",
        "colab_type": "code",
        "outputId": "48bf7851-21f3-42a8-ccbf-3d56c78e085c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLt50F-bXzUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    #ResNet-18 \n",
        "    #net = ResNet(baseBlock,[2,2,2,2],10)\n",
        "\n",
        "    #ResNet-50\n",
        "    net =  ResNet(bottleNeck,[3,4,6,3])\n",
        "    net.to(device)\n",
        "    costFunc = torch.nn.CrossEntropyLoss()\n",
        "    optimizer =  torch.optim.SGD(net.parameters(),lr=0.02,momentum=0.9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gvtBVghX19T",
        "colab_type": "code",
        "outputId": "78171569-7d02-48d9-d0a5-2a39585a1c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "source": [
        "for epoch in range(40):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for batch in trainset: # Get Batch # completed 6000 image in single epoch with \n",
        "                               # batch size 100 \n",
        "        images, labels = batch \n",
        "\n",
        "        preds = net(images) # Pass Batch\n",
        "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "\n",
        "        optimizer.zero_grad() # doning zero grad value after every mini batch \n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() # Update Weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += get_num_correct(preds, labels)\n",
        "\n",
        "    print(\n",
        "        \"epoch\", epoch, \n",
        "        \"total_correct:\", total_correct, \n",
        "        \"loss:\", total_loss\n",
        "    )\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 total_correct: 29 loss: 8.062977731227875\n",
            "epoch 1 total_correct: 26 loss: 6.365553706884384\n",
            "epoch 2 total_correct: 25 loss: 8.498347461223602\n",
            "epoch 3 total_correct: 22 loss: 24.126697778701782\n",
            "epoch 4 total_correct: 20 loss: 17.57391881942749\n",
            "epoch 5 total_correct: 20 loss: 9.64309960603714\n",
            "epoch 6 total_correct: 21 loss: 9.335699260234833\n",
            "epoch 7 total_correct: 25 loss: 7.270875781774521\n",
            "epoch 8 total_correct: 18 loss: 11.075202286243439\n",
            "epoch 9 total_correct: 24 loss: 18.269697904586792\n",
            "epoch 10 total_correct: 21 loss: 5.755823791027069\n",
            "epoch 11 total_correct: 24 loss: 8.389845132827759\n",
            "epoch 12 total_correct: 25 loss: 7.102871775627136\n",
            "epoch 13 total_correct: 31 loss: 2.9284922182559967\n",
            "epoch 14 total_correct: 26 loss: 4.264733821153641\n",
            "epoch 15 total_correct: 22 loss: 4.580765664577484\n",
            "epoch 16 total_correct: 25 loss: 8.147618442773819\n",
            "epoch 17 total_correct: 27 loss: 7.339573383331299\n",
            "epoch 18 total_correct: 30 loss: 6.011737644672394\n",
            "epoch 19 total_correct: 27 loss: 4.902013421058655\n",
            "epoch 20 total_correct: 31 loss: 2.595928281545639\n",
            "epoch 21 total_correct: 26 loss: 16.693892776966095\n",
            "epoch 22 total_correct: 29 loss: 7.747152924537659\n",
            "epoch 23 total_correct: 32 loss: 2.425725430250168\n",
            "epoch 24 total_correct: 27 loss: 3.3786322474479675\n",
            "epoch 25 total_correct: 31 loss: 2.116813600063324\n",
            "epoch 26 total_correct: 28 loss: 4.0586026310920715\n",
            "epoch 27 total_correct: 29 loss: 7.211074143648148\n",
            "epoch 28 total_correct: 30 loss: 3.9531250298023224\n",
            "epoch 29 total_correct: 29 loss: 3.1162983775138855\n",
            "epoch 30 total_correct: 27 loss: 7.641364485025406\n",
            "epoch 31 total_correct: 27 loss: 2.5140100717544556\n",
            "epoch 32 total_correct: 24 loss: 4.961659848690033\n",
            "epoch 33 total_correct: 27 loss: 4.647431820631027\n",
            "epoch 34 total_correct: 28 loss: 5.495492219924927\n",
            "epoch 35 total_correct: 33 loss: 2.081762135028839\n",
            "epoch 36 total_correct: 25 loss: 6.417880594730377\n",
            "epoch 37 total_correct: 21 loss: 3.922228217124939\n",
            "epoch 38 total_correct: 23 loss: 8.37323373556137\n",
            "epoch 39 total_correct: 28 loss: 5.588818728923798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwOarXnIv5DE",
        "colab_type": "code",
        "outputId": "d1daeb90-4d64-43bf-c307-3a38662372c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "        correctHits=0\n",
        "        total=0\n",
        "        for batches in trainset:\n",
        "            data,output = batches\n",
        "            data,output = data.to(device),output.to(device)\n",
        "            prediction = net(data)\n",
        "            _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
        "            total += output.size(0)\n",
        "            correctHits += (prediction==output).sum().item()\n",
        "        print('Accuracy on epoch ',epoch+1,'= ',str((correctHits/total)*100))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on epoch  40 =  66.66666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfcwy78QxaJ-",
        "colab_type": "code",
        "outputId": "57e9247d-4a12-4e04-83ae-fa1b15117366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "    correctHits=0\n",
        "    total=0\n",
        "    for batches in trainset:\n",
        "        data,output = batches\n",
        "        data,output = data.to(device),output.to(device)\n",
        "        prediction = net(data)\n",
        "        _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
        "        total += output.size(0)\n",
        "        correctHits += (prediction==output).sum().item()\n",
        "    print('Accuracy = '+str((correctHits/total)*100))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 69.04761904761905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Z45naDxuIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}